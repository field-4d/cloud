# Field4D StatDeck

A high-performance FastAPI service for performing statistical testing on time-series group comparisons with intelligent batching and validation.

## ğŸ—ï¸ Application Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Field4D StatDeck                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   FastAPI App   â”‚    â”‚  Stat Engine    â”‚    â”‚   Config     â”‚ â”‚
â”‚  â”‚   (main.py)     â”‚â—„â”€â”€â–ºâ”‚ (stat_engine.py)â”‚â—„â”€â”€â–ºâ”‚ (config.py)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                       â”‚                             â”‚
â”‚           â–¼                       â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  Data Models    â”‚    â”‚  Batch Validationâ”‚                     â”‚
â”‚  â”‚(test_models.py) â”‚    â”‚   & Rules       â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Statistical Tests Supported

| Test Type | Status | Implementation | Description |
|-----------|--------|----------------|-------------|
| **Tukey's HSD** | âœ… **Active** | `run_anova_tukey()` | ANOVA with post-hoc Tukey's Honestly Significant Difference test |
| **T-Test** | ğŸ”„ **Pending** | `run_t_test()` | Independent samples t-test (placeholder) |
| **Dunnett's Test** | ğŸ”„ **Pending** | `run_dunnett()` | Multiple comparisons vs control (placeholder) |

## ğŸš€ API Endpoints

### Health Check
```
GET /health
```
Returns service status and batch validation rules.

### Statistical Analysis Endpoints

#### 1. Tukey's HSD Test
```
POST /analyze/tukey
```
**Request Body:**
```json
{
  "parameter": "SoilMoisture",
  "alpha": 0.05,
  "data": [
    {"timestamp": "2025-06-01", "label": "Control", "value": 18.0},
    {"timestamp": "2025-06-01", "label": "TreatmentA", "value": 21.3},
    {"timestamp": "2025-06-02", "label": "Control", "value": 19.1},
    {"timestamp": "2025-06-02", "label": "TreatmentA", "value": 24.4}
  ]
}
```

**Response:**
```json
{
  "parameter": "SoilMoisture",
  "test_type": "tukey",
  "batch_size": 4,
  "results": [
    {
      "timestamp": "2025-06-01",
      "groups_tested": ["Control", "TreatmentA"],
      "group_stats": {
        "Control": {"mean": 18.0, "standard_error": 0.0, "n": 1},
        "TreatmentA": {"mean": 21.3, "standard_error": 0.0, "n": 1}
      },
      "significant_differences": [
        {
          "comparison": "Control vs TreatmentA",
          "p_value": 0.045,
          "reject_null": true
        }
      ],
      "letters_report": {"Control": "A", "TreatmentA": "B"}
    }
  ]
}
```

#### 2. T-Test (Pending Implementation)
```
POST /analyze/t-test
```
Returns HTTP 202 (Accepted) with placeholder response.

#### 3. Dunnett's Test (Pending Implementation)
```
POST /analyze/dunnett
```
Returns HTTP 202 (Accepted) with placeholder response.

#### 4. Legacy Endpoint (Deprecated)
```
POST /analyze
```
Backward compatibility endpoint - use specific test endpoints instead.

## ğŸ“ˆ Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client Data   â”‚â”€â”€â”€â–ºâ”‚  Batch Validationâ”‚â”€â”€â”€â–ºâ”‚  Data Processingâ”‚
â”‚   (JSON Input)  â”‚    â”‚   (config.py)   â”‚    â”‚  (stat_engine.py)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â–¼                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Validation Rulesâ”‚    â”‚ Statistical Testsâ”‚
                       â”‚                 â”‚    â”‚                 â”‚
                       â”‚ â‰¤ 50K: 10K max  â”‚    â”‚ â€¢ ANOVA         â”‚
                       â”‚ â‰¤ 100K: 10K max â”‚    â”‚ â€¢ Tukey's HSD   â”‚
                       â”‚ â‰¤ 500K: 5K max  â”‚    â”‚ â€¢ Group Stats   â”‚
                       â”‚ > 500K: 3K max  â”‚    â”‚ â€¢ Letters Reportâ”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚  Results Output â”‚
                                              â”‚   (JSON Response)â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Batch Validation Rules

The application implements intelligent batch size validation based on dataset size:

| Dataset Size | Maximum Batch Size | Rationale |
|--------------|-------------------|-----------|
| â‰¤ 50K points | 10,000 | Optimal performance for small datasets |
| â‰¤ 100K points | 10,000 | Balanced processing for medium datasets |
| â‰¤ 500K points | 5,000 | Memory management for large datasets |
| > 500K points | 3,000 | Resource optimization for very large datasets |

## ğŸ“ Project Structure

```
field4d-statdeck/
â”œâ”€â”€ app/                          # Main application code
â”‚   â”œâ”€â”€ __init__.py              # Package initialization
â”‚   â”œâ”€â”€ main.py                  # FastAPI application entry point
â”‚   â”œâ”€â”€ stat_engine.py           # Statistical analysis engine
â”‚   â”œâ”€â”€ test_models.py           # Pydantic data models
â”‚   â””â”€â”€ config.py                # Configuration and validation rules
â”œâ”€â”€ test_data/                   # Test datasets and results
â”‚   â”œâ”€â”€ API_test_output/         # API testing results
â”‚   â”‚   â”œâ”€â”€ Batching/           # Batch processing tests
â”‚   â”‚   â”œâ”€â”€ General/            # General API tests
â”‚   â”‚   â””â”€â”€ Optimized_Batching/ # Optimized batch tests
â”‚   â”œâ”€â”€ example_input.json      # Sample input data
â”‚   â””â”€â”€ example_input_many_groups.json
â”œâ”€â”€ test_FastAPI/               # FastAPI testing utilities
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ API_DOCUMENTATION.md        # Detailed API documentation
â””â”€â”€ README.md                   # This file
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.8+
- pip package manager

### Installation Steps

1. **Clone the repository:**
```bash
git clone <repository-url>
cd field4d-statdeck
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Run the application:**
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `LOG_LEVEL` | `INFO` | Logging level (DEBUG, INFO, WARNING, ERROR) |
| `MAX_REQUEST_SIZE` | `1000000` | Maximum request size in bytes (1MB) |

## ğŸ§ª Testing

### Manual Testing
```bash
# Test health endpoint
curl http://localhost:8000/health

# Test Tukey endpoint
curl -X POST http://localhost:8000/analyze/tukey \
  -H "Content-Type: application/json" \
  -d @test_data/example_input.json
```

### Automated Testing
The project includes comprehensive test suites in the `test_data/` directory with various scenarios and batch sizes.

## ğŸ“Š Performance Characteristics

- **Response Time**: < 2 seconds for batches up to 10K points
- **Memory Usage**: Optimized for large datasets with intelligent batching
- **Scalability**: Horizontal scaling ready with stateless design
- **Validation**: Automatic batch size validation with clear error messages

## ğŸ” Key Features

### 1. **Intelligent Batching**
- Automatic batch size validation based on dataset size
- Clear error messages with recommended batch sizes
- Performance optimization for different data scales

### 2. **Comprehensive Statistical Analysis**
- ANOVA with Tukey's HSD post-hoc testing
- Group statistics (mean, standard error, sample size)
- Letters report for significant differences
- Per-timestamp analysis for time-series data

### 3. **Robust Error Handling**
- Detailed error messages for statistical failures
- Input validation with Pydantic models
- Graceful handling of edge cases

### 4. **API Documentation**
- Interactive Swagger UI at `/docs`
- OpenAPI specification
- Example requests and responses

## ğŸš€ Deployment

### Local Development
```bash
uvicorn app.main:app --reload
```

### Production Deployment
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Docker Deployment
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY app/ ./app/
EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ“ Data Format

### Input Data Structure
```json
{
  "parameter": "string",     // Parameter name (e.g., "SoilMoisture")
  "alpha": 0.05,            // Significance level (optional, default: 0.05)
  "data": [
    {
      "timestamp": "string", // ISO format timestamp
      "label": "string",     // Group label
      "value": float         // Numeric measurement
    }
  ]
}
```

### Output Data Structure
```json
{
  "parameter": "string",
  "test_type": "string",
  "batch_size": integer,
  "results": [
    {
      "timestamp": "string",
      "groups_tested": ["string"],
      "group_stats": {
        "group_name": {
          "mean": float,
          "standard_error": float,
          "n": integer
        }
      },
      "significant_differences": [
        {
          "comparison": "string",
          "p_value": float,
          "reject_null": boolean
        }
      ],
      "letters_report": {
        "group_name": "string"
      }
    }
  ]
}
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For issues and questions:
- Check the API documentation at `/docs`
- Review test examples in `test_data/`
- Open an issue on the repository

---

**Field4D StatDeck** - Statistical analysis for time-series group comparisons with intelligent batching and validation. 